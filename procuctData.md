# 运算符、广播机制、转换为其他Python对象、索引和切片


```python
import torch
```

张量表示由一个数值组成的数组，这个数组可能有多个维度。 具有一个轴的张量对应数学上的向量（vector）； 具有两个轴的张量对应数学上的矩阵（matrix）； 具有两个轴以上的张量没有特殊的数学名称。

首先，可以使用arange创建一个行向量x。 这个行向量包含从0开始的前12个整数，它们被默认创建为浮点数。 张量中的每个值都称为张量的元素（element）。 例如，张量x中有12个元素。 除非额外指定，新的张量默认将存储在内存中，并采用基于CPU的计算。


```python
x = torch.arange(12)
```


```python
x
```




    tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])



张量的形状


```python
x.shape
```




    torch.Size([12])



张量中元素的总数


```python
x.numel()
```




    12



要想改变一个张量的形状而不改变元素数量和元素值，可以调用reshape函数。 例如，可以把张量x从形状为（12,）的行向量转换为形状为（3,4）的矩阵。 这个新的张量包含与转换前相同的值，但是它被看成一个3行4列的矩阵。 要重点说明一下，虽然张量的形状发生了改变，但其元素值并没有变。 注意，通过改变张量的形状，张量的大小不会改变。



```python
x.reshape(3,4)
```




    tensor([[ 0,  1,  2,  3],
            [ 4,  5,  6,  7],
            [ 8,  9, 10, 11]])



我们希望使用全0、全1、其他常量，或者从特定分布中随机采样的数字来初始化矩阵。 我们可以创建一个形状为（2,3,4）的张量，其中所有元素都设置为0。


```python
torch.zeros(3,3,3)
```




    tensor([[[0., 0., 0.],
             [0., 0., 0.],
             [0., 0., 0.]],
    
            [[0., 0., 0.],
             [0., 0., 0.],
             [0., 0., 0.]],
    
            [[0., 0., 0.],
             [0., 0., 0.],
             [0., 0., 0.]]])




```python
torch.ones(2,3,3)
```




    tensor([[[1., 1., 1.],
             [1., 1., 1.],
             [1., 1., 1.]],
    
            [[1., 1., 1.],
             [1., 1., 1.],
             [1., 1., 1.]]])



通过从某个特定的概率分布中随机采样来得到张量中每个元素的值

随机初始化参数的值.其中的每个元素都从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样。


```python
torch.randn(3,3)
```




    tensor([[-0.7589,  0.2146,  1.3089],
            [ 0.5054, -1.2099,  0.0549],
            [ 0.4887, -0.3969,  2.3525]])



我们还可以通过提供包含数值的Python列表（或嵌套列表），来为所需张量中的每个元素赋予确定值。 在这里，最外层的列表对应于轴0，内层的列表对应于轴1。


```python
torch.tensor([[2,3,4],[5,6,7]])
```




    tensor([[2, 3, 4],
            [5, 6, 7]])



# 2.1.2. 运算符


```python
x = torch.randn(3,3)
```


```python
x
```




    tensor([[-0.5632, -0.2691, -1.2166],
            [ 2.8245,  0.3242, -0.4493],
            [ 2.0948, -1.7967,  1.0118]])




```python
x[:2]
```




    tensor([[-0.5632, -0.2691, -1.2166],
            [ 2.8245,  0.3242, -0.4493]])



对于任意具有相同形状的张量， 常见的标准算术运算符（+、-、*、/和**）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作


```python
a  = torch.randn(2,4,4)
b  = torch.randn(2,4,4)
```


```python
a,b
```




    (tensor([[[-0.6862, -1.3662,  0.5719, -0.2174],
              [-0.6651,  0.2537, -1.9083,  0.6966],
              [ 0.3378,  0.2629,  1.0715, -0.6062],
              [ 0.8331,  1.8958, -0.5320, -0.3592]],
     
             [[ 0.8307,  0.0870,  0.8067, -1.0113],
              [ 2.4886, -0.4792,  0.0200, -1.8460],
              [ 2.1249,  0.5802, -1.4602,  1.2101],
              [-0.3491, -1.5177, -0.7814, -0.6185]]]),
     tensor([[[-2.3884,  0.8273,  0.2483, -0.8992],
              [ 1.1061,  1.5241, -1.0873, -1.2618],
              [ 1.0232, -0.3435,  0.8593, -0.5322],
              [ 0.2929, -1.5916,  1.0746,  1.6550]],
     
             [[-1.0793,  0.6453,  0.1192, -1.2552],
              [ 0.0987,  0.2672,  1.8677,  0.0681],
              [-0.1410, -1.5440,  0.6439,  0.1095],
              [-0.3411, -0.2075,  1.1420,  1.3812]]]))




```python
a+b,a*b,a-b,a/b,a**b #**运算符是求幂运算
```




    (tensor([[[-3.0746, -0.5389,  0.8202, -1.1165],
              [ 0.4410,  1.7778, -2.9955, -0.5652],
              [ 1.3610, -0.0806,  1.9309, -1.1384],
              [ 1.1260,  0.3042,  0.5426,  1.2958]],
     
             [[-0.2486,  0.7323,  0.9259, -2.2665],
              [ 2.5873, -0.2120,  1.8877, -1.7779],
              [ 1.9838, -0.9638, -0.8163,  1.3196],
              [-0.6901, -1.7252,  0.3606,  0.7627]]]),
     tensor([[[ 1.6390, -1.1302,  0.1420,  0.1954],
              [-0.7357,  0.3867,  2.0748, -0.8789],
              [ 0.3456, -0.0903,  0.9208,  0.3226],
              [ 0.2441, -3.0172, -0.5717, -0.5945]],
     
             [[-0.8965,  0.0561,  0.0962,  1.2694],
              [ 0.2455, -0.1280,  0.0374, -0.1257],
              [-0.2996, -0.8957, -0.9402,  0.1325],
              [ 0.1191,  0.3149, -0.8923, -0.8543]]]),
     tensor([[[ 1.7022, -2.1935,  0.3236,  0.6818],
              [-1.7712, -1.2705, -0.8210,  1.9584],
              [-0.6854,  0.6064,  0.2122, -0.0740],
              [ 0.5402,  3.4873, -1.6066, -2.0142]],
     
             [[ 1.9100, -0.5584,  0.6875,  0.2439],
              [ 2.3900, -0.7464, -1.8477, -1.9141],
              [ 2.2659,  2.1241, -2.1041,  1.1006],
              [-0.0080, -1.3102, -1.9234, -1.9998]]]),
     tensor([[[ 2.8731e-01, -1.6514e+00,  2.3030e+00,  2.4174e-01],
              [-6.0132e-01,  1.6645e-01,  1.7551e+00, -5.5207e-01],
              [ 3.3017e-01, -7.6539e-01,  1.2469e+00,  1.1390e+00],
              [ 2.8440e+00, -1.1911e+00, -4.9505e-01, -2.1704e-01]],
     
             [[-7.6963e-01,  1.3474e-01,  6.7659e+00,  8.0569e-01],
              [ 2.5226e+01, -1.7936e+00,  1.0712e-02, -2.7111e+01],
              [-1.5070e+01, -3.7576e-01, -2.2678e+00,  1.1051e+01],
              [ 1.0233e+00,  7.3139e+00, -6.8426e-01, -4.4780e-01]]]),
     tensor([[[       nan,        nan, 8.7043e-01,        nan],
              [       nan, 1.2361e-01,        nan, 1.5781e+00],
              [3.2943e-01, 1.5823e+00, 1.0612e+00,        nan],
              [9.4792e-01, 3.6132e-01,        nan,        nan]],
     
             [[1.2217e+00, 2.0677e-01, 9.7471e-01,        nan],
              [1.0941e+00,        nan, 6.7159e-04,        nan],
              [8.9918e-01, 2.3178e+00,        nan, 1.0211e+00],
              [       nan,        nan,        nan,        nan]]]))




```python
torch.exp(a)
```




    tensor([[[ 0.5035,  0.2551,  1.7716,  0.8046],
             [ 0.5142,  1.2888,  0.1483,  2.0069],
             [ 1.4019,  1.3007,  2.9199,  0.5454],
             [ 2.3005,  6.6576,  0.5874,  0.6982]],
    
            [[ 2.2948,  1.0908,  2.2405,  0.3637],
             [12.0445,  0.6193,  1.0202,  0.1579],
             [ 8.3716,  1.7863,  0.2322,  3.3537],
             [ 0.7054,  0.2192,  0.4578,  0.5387]]])



我们也可以把多个张量连结（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况。 我们可以看到，第一个输出张量的轴-0长度（ 6 ）是两个输入张量轴-0长度的总和（ 3+3 ）； 第二个输出张量的轴-1长度（ 8 ）是两个输入张量轴-1长度的总和（ 4+4 ）。


```python
a,b,torch.cat((a,b),dim=0)
```




    (tensor([[[-0.6862, -1.3662,  0.5719, -0.2174],
              [-0.6651,  0.2537, -1.9083,  0.6966],
              [ 0.3378,  0.2629,  1.0715, -0.6062],
              [ 0.8331,  1.8958, -0.5320, -0.3592]],
     
             [[ 0.8307,  0.0870,  0.8067, -1.0113],
              [ 2.4886, -0.4792,  0.0200, -1.8460],
              [ 2.1249,  0.5802, -1.4602,  1.2101],
              [-0.3491, -1.5177, -0.7814, -0.6185]]]),
     tensor([[[-2.3884,  0.8273,  0.2483, -0.8992],
              [ 1.1061,  1.5241, -1.0873, -1.2618],
              [ 1.0232, -0.3435,  0.8593, -0.5322],
              [ 0.2929, -1.5916,  1.0746,  1.6550]],
     
             [[-1.0793,  0.6453,  0.1192, -1.2552],
              [ 0.0987,  0.2672,  1.8677,  0.0681],
              [-0.1410, -1.5440,  0.6439,  0.1095],
              [-0.3411, -0.2075,  1.1420,  1.3812]]]),
     tensor([[[-0.6862, -1.3662,  0.5719, -0.2174],
              [-0.6651,  0.2537, -1.9083,  0.6966],
              [ 0.3378,  0.2629,  1.0715, -0.6062],
              [ 0.8331,  1.8958, -0.5320, -0.3592]],
     
             [[ 0.8307,  0.0870,  0.8067, -1.0113],
              [ 2.4886, -0.4792,  0.0200, -1.8460],
              [ 2.1249,  0.5802, -1.4602,  1.2101],
              [-0.3491, -1.5177, -0.7814, -0.6185]],
     
             [[-2.3884,  0.8273,  0.2483, -0.8992],
              [ 1.1061,  1.5241, -1.0873, -1.2618],
              [ 1.0232, -0.3435,  0.8593, -0.5322],
              [ 0.2929, -1.5916,  1.0746,  1.6550]],
     
             [[-1.0793,  0.6453,  0.1192, -1.2552],
              [ 0.0987,  0.2672,  1.8677,  0.0681],
              [-0.1410, -1.5440,  0.6439,  0.1095],
              [-0.3411, -0.2075,  1.1420,  1.3812]]]))




```python
a,b,torch.cat((a,b),dim=1)
```




    (tensor([[[-0.6862, -1.3662,  0.5719, -0.2174],
              [-0.6651,  0.2537, -1.9083,  0.6966],
              [ 0.3378,  0.2629,  1.0715, -0.6062],
              [ 0.8331,  1.8958, -0.5320, -0.3592]],
     
             [[ 0.8307,  0.0870,  0.8067, -1.0113],
              [ 2.4886, -0.4792,  0.0200, -1.8460],
              [ 2.1249,  0.5802, -1.4602,  1.2101],
              [-0.3491, -1.5177, -0.7814, -0.6185]]]),
     tensor([[[-2.3884,  0.8273,  0.2483, -0.8992],
              [ 1.1061,  1.5241, -1.0873, -1.2618],
              [ 1.0232, -0.3435,  0.8593, -0.5322],
              [ 0.2929, -1.5916,  1.0746,  1.6550]],
     
             [[-1.0793,  0.6453,  0.1192, -1.2552],
              [ 0.0987,  0.2672,  1.8677,  0.0681],
              [-0.1410, -1.5440,  0.6439,  0.1095],
              [-0.3411, -0.2075,  1.1420,  1.3812]]]),
     tensor([[[-0.6862, -1.3662,  0.5719, -0.2174],
              [-0.6651,  0.2537, -1.9083,  0.6966],
              [ 0.3378,  0.2629,  1.0715, -0.6062],
              [ 0.8331,  1.8958, -0.5320, -0.3592],
              [-2.3884,  0.8273,  0.2483, -0.8992],
              [ 1.1061,  1.5241, -1.0873, -1.2618],
              [ 1.0232, -0.3435,  0.8593, -0.5322],
              [ 0.2929, -1.5916,  1.0746,  1.6550]],
     
             [[ 0.8307,  0.0870,  0.8067, -1.0113],
              [ 2.4886, -0.4792,  0.0200, -1.8460],
              [ 2.1249,  0.5802, -1.4602,  1.2101],
              [-0.3491, -1.5177, -0.7814, -0.6185],
              [-1.0793,  0.6453,  0.1192, -1.2552],
              [ 0.0987,  0.2672,  1.8677,  0.0681],
              [-0.1410, -1.5440,  0.6439,  0.1095],
              [-0.3411, -0.2075,  1.1420,  1.3812]]]))



或许有些简单的例子


```python
X = torch.arange(12, dtype=torch.float32).reshape((3,4))
Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
```


```python
X,,torch.cat((X, Y), dim=0)
```




    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.]]),
     tensor([[2., 1., 4., 3.],
             [1., 2., 3., 4.],
             [4., 3., 2., 1.]]),
     tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.],
             [ 2.,  1.,  4.,  3.],
             [ 1.,  2.,  3.,  4.],
             [ 4.,  3.,  2.,  1.]]))




```python
X,Y,torch.cat((X, Y), dim=1)
```




    (tensor([[ 0.,  1.,  2.,  3.],
             [ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.]]),
     tensor([[2., 1., 4., 3.],
             [1., 2., 3., 4.],
             [4., 3., 2., 1.]]),
     tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],
             [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],
             [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))



有时，我们想通过逻辑运算符构建二元张量。 以X == Y为例： 对于每个位置，如果X和Y在该位置相等，则新张量中相应项的值为1。 这意味着逻辑语句X == Y在该位置处为真，否则该位置为0。




```python
X ==Y
```




    tensor([[False,  True, False,  True],
            [False, False, False, False],
            [False, False, False, False]])



对张量中的所有元素进行求和，会产生一个单元素张量


```python
a.sum()
```




    tensor(-0.3326)



# 广播机制

上面是形状相同的两个张量进行操作，但是实际的场景中形状往往不同，我们可以调用广播机制来执行按元素操作

这种机制的工作方式如下：首先，通过适当复制元素来扩展一个或两个数组， 以便在转换之后，两个张量具有相同的形状。 其次，对生成的数组执行按元素操作。


```python
a1 = torch.rand(3,1)
a2 = torch.rand(1,6)
```


```python
a1,a2
```




    (tensor([[0.2217],
             [0.9356],
             [0.8031]]),
     tensor([[0.8955, 0.6774, 0.7718, 0.9322, 0.3640, 0.5841]]))




```python
a1+a2
```




    tensor([[1.1172, 0.8992, 0.9935, 1.1539, 0.5857, 0.8059],
            [1.8311, 1.6130, 1.7074, 1.8678, 1.2996, 1.5197],
            [1.6986, 1.4805, 1.5748, 1.7353, 1.1671, 1.3872]])



a1和a2分别是3*1和1*6的矩阵，如果按照常规操作是不能进行相加的，因为他们的形状不匹配
我们将两个矩阵广播为一个更大的 3×6 矩阵，如下所示：矩阵a1将复制列， 矩阵a2将复制行，然后再按元素相加。


```python
a1+a2# 这里有问题就是如果矩阵是3*4和2*6 不能运算
```




    tensor([[1.1172, 0.8992, 0.9935, 1.1539, 0.5857, 0.8059],
            [1.8311, 1.6130, 1.7074, 1.8678, 1.2996, 1.5197],
            [1.6986, 1.4805, 1.5748, 1.7353, 1.1671, 1.3872]])




```python
a = torch.arange(3).reshape((3, 1))
b = torch.arange(2).reshape((1, 2))
a, b,a+b
```




    (tensor([[0],
             [1],
             [2]]),
     tensor([[0, 1]]),
     tensor([[0, 1],
             [1, 2],
             [2, 3]]))



# 索引和切片

就像在任何其他Python数组中一样，张量中的元素可以通过索引访问。 与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。

如下所示，我们可以用[-1]选择最后一个元素，可以用[1:3]选择第二个和第三个元素：


```python
X[-1], X[1:3]
```




    (tensor([ 8.,  9., 10., 11.]),
     tensor([[ 4.,  5.,  6.,  7.],
             [ 8.,  9., 10., 11.]]))



除读取外，我们还可以通过指定索引来将元素写入矩阵。


```python
X[1, 2] = 9
X
```




    tensor([[ 0.,  1.,  2.,  3.],
            [ 4.,  5.,  9.,  7.],
            [ 8.,  9., 10., 11.]])



如果我们想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。 例如，[0:2, :]访问第1行和第2行，其中“:”代表沿轴1（列）的所有元素。 虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。


```python
X[0:2, :] = 12
X
```




    tensor([[12., 12., 12., 12.],
            [12., 12., 12., 12.],
            [ 8.,  9., 10., 11.]])



# 转换为其他Python对象


```python
A= a.numpy()
```


```python
A
```




    array([[0],
           [1],
           [2]], dtype=int64)




```python
B = torch.tensor(A)
```


```python
B
```




    tensor([[0],
            [1],
            [2]])




```python
a = X[2,3]
```

要将大小为1的张量转换为Python标量，我们可以调用item函数或Python的内置函数,
取矩阵中的一个数，转换为标量


```python
X,a
```




    (tensor([[12., 12., 12., 12.],
             [12., 12., 12., 12.],
             [ 8.,  9., 10., 11.]]),
     tensor(11.))




```python
a, a.item(), float(a), int(a)
```




    (tensor(11.), 11.0, 11.0, 11)




```python

```


```python

```


```python

```


```python

```


```python

```


```python

```
